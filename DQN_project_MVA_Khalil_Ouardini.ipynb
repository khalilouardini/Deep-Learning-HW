{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epsilon allows exploration of new states to avoid getting stuck in the exploitation of a greedy policy (In other words, it prevents from being stuck in local maximas).\n",
    "For a given phase (either train or test) and at the current state of the game, the act function returns the action to take at the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=47 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position: ($(N+4)\\times(N+4)$ array with value -1 for forbidden positions (board frame), 1 for the current rat position, and 0 otherwise) allows to keep track of the rat position.\n",
    "\n",
    "\n",
    "board: ($(N+4)\\times(N+4)$ array with value 0.5 if a cheese is on the cell, -1 if a poison is on the cell and 0 otherwise) allows to evaluate the given bonus/malus of a given action from a given state.\n",
    "\n",
    "actions & reward: up$\\rightarrow$0 | \n",
    "                  down$\\rightarrow$ |\n",
    "                  left$\\rightarrow$2 |\n",
    "                  right$\\rightarrow$3 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        ##### FILL IN HERE\n",
    "        \n",
    "        # At each epoch, we restart and get the initial state\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "\n",
    "        win, lose = 0, 0\n",
    "\n",
    "        while not game_over:\n",
    "            # agent takes action\n",
    "            action = agent.learned_act(state)\n",
    "\n",
    "            #Update: next state, reward from the environment\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "\n",
    "        # Update stats\n",
    "        score += win - lose\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))\n",
    " \n",
    "# for the last question\n",
    "def test_explore(agent, env, epochs, prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.learned_act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, exploration_reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "\n",
    "        # Update stats\n",
    "        score += win - lose\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix + str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win - lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Win/lose count 0/0. Average score (0.0)\n",
      "Final score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer**\n",
    "$$\n",
    "Q^\\pi(s,a) \\\\\n",
    "= E_\\pi\\left[\\sum_{t\\geq 0}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a\\right] \\\\\n",
    "= r(s,a) + E_\\pi\\left[\\sum_{t\\geq 1}\\gamma^t r(s_t, a_t)|s_{0}=s,a_{0}=a\\right] \n",
    "$$\n",
    "\n",
    "As\n",
    "\n",
    "$$\n",
    "E_\\pi\\left[\\sum_{t\\geq 1}\\gamma^t r(s_t, a_t)|s_{0}=s,a_{0}=a\\right] \\\\\n",
    "= \\gamma\\sum_{s', a'}P_\\pi(s_1=s', a_1=a' | s_0=s, a_0=a)E_\\pi\\left[\\sum_{t\\geq 1}\\gamma^{t-1}r(s_t, a_t)|s_1=s', a_1=a'\\right]\n",
    "$$\n",
    "It comes that\n",
    "\n",
    "$$\n",
    "Q^\\pi(s,a) = r(s, a) + \\gamma E_{(s',a')\\sim \\pi(.|s,a)}[Q^\\pi(s',a')]\n",
    "$$\n",
    "Since $\\pi^*$ is an optimal policy:\n",
    "\n",
    "$$\n",
    "Q^*(s,a) \\\\\n",
    "= \\max_{\\pi}Q^\\pi(s, a)\\\\\n",
    "= r(s,a) + \\gamma\\max_\\pi E_{(s', a')\\sim\\pi(\\cdot|s,a)}[Q^\\pi(s', a')]\n",
    "$$\n",
    "But\n",
    "\n",
    "$$\n",
    "\\max_\\pi E_{(s', a')\\sim\\pi(\\cdot|s,a)}[Q^\\pi(s', a')]\\\\\n",
    "= \\max_{a' \\pi'}E_{s'\\sim\\pi'(\\cdot|s,a)}[Q^{\\pi'}(s', a')]\\\\\n",
    "= E_{s'\\sim\\pi^*(\\cdot|s,a)}[\\max_{a'}Q^{\\pi^*}(s', a')] \n",
    "$$\n",
    "Hence\n",
    "\n",
    "$$\n",
    "Q^*(s,a) = r(s,a) + \\gamma E_{s'\\sim\\pi^*(\\cdot|s,a)}[\\max_{a'}Q^{\\pi^*}(s', a')] \n",
    "$$\n",
    "\n",
    "Let $Q(s, a, \\theta)$ denote the critic network parametrization. Naturally, if acting on state action pair $(s, a)$ one would want to minimize the gap between the greedy Q-value and the actual one i.e. $\\mathcal{L}(^*Q(s, a, \\theta) - Q(s, a , \\theta))$ where $\\mathcal{L}$ denotes a loss function.\n",
    "\n",
    "therefore we can define the following loss function :\n",
    "\n",
    "$$ \\mathcal{L}(\\theta) = E_{s'\\sim \\pi^*(.|s,a)}[||Q^*(s,a) - Q(s,a,\\theta)||^2] $$\n",
    "\n",
    "By using the result of the previous question $$Q^*(s,a) = E_{s'\\sim \\pi^*(.|s,a)}[r(s,a) + \\gamma max_{a'}Q^*(s',a')] $$\n",
    "\n",
    "The final loss is therefore:\n",
    "\n",
    "$$ \\mathcal{L}(\\theta) = E_{s'\\sim \\pi^*(.|s,a)}[|| r(s,a) + \\gamma max_{a'}Q^*(s',a') - Q(s,a,\\theta) ||^2]$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        self.memory.insert(0, m)\n",
    "        if len(self.memory) > self.max_memory:\n",
    "            del self.memory[-1]\n",
    "\n",
    "    def random_access(self):\n",
    "        return random.choice(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16, n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Critic network\n",
    "        self.model = None\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        actions_likelihood = self.model.predict(np.expand_dims(s, 0))\n",
    "        return np.argmax(actions_likelihood)\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        ######## FILL IN\n",
    "        for i in range(self.batch_size):\n",
    "            #[state, next_state, action, reward, game_over] = self.memory.random_access()\n",
    "            [s_, n_s_, a_, r_, g_o_] = self.memory.random_access()\n",
    "            input_states[i] = s_\n",
    "            target_q[i] = self.model.predict(np.expand_dims(s_, 0))\n",
    "            # update Q star\n",
    "            ######## FILL IN\n",
    "            if g_o_:\n",
    "                target_q[i, a_] = r_\n",
    "            ######## FILL IN\n",
    "            else:\n",
    "                greedy_q_value = np.max(self.model.predict(np.expand_dims(n_s_, 0)))\n",
    "                target_q[i, a_] = r_ + self.discount * greedy_q_value\n",
    "                \n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "        return l\n",
    "\n",
    "    def save(self, name_weights='model.h5', name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self, name_weights='model.h5', name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=(5, 5, self.n_state)))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From //anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 000/047 | Loss 0.0124 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 001/047 | Loss 0.0016 | Win/lose count 2.0/5.0 (-3.0)\n",
      "Epoch 002/047 | Loss 0.0038 | Win/lose count 5.5/4.0 (1.5)\n",
      "Epoch 003/047 | Loss 0.0118 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 004/047 | Loss 0.0022 | Win/lose count 3.5/5.0 (-1.5)\n",
      "Epoch 005/047 | Loss 0.0005 | Win/lose count 2.5/6.0 (-3.5)\n",
      "Epoch 006/047 | Loss 0.0101 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 007/047 | Loss 0.0191 | Win/lose count 1.0/8.0 (-7.0)\n",
      "Epoch 008/047 | Loss 0.0003 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 009/047 | Loss 0.0240 | Win/lose count 5.5/7.0 (-1.5)\n",
      "Epoch 010/047 | Loss 0.0033 | Win/lose count 4.0/2.0 (2.0)\n",
      "Epoch 011/047 | Loss 0.0108 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 012/047 | Loss 0.0089 | Win/lose count 3.5/7.0 (-3.5)\n",
      "Epoch 013/047 | Loss 0.0008 | Win/lose count 4.0/6.0 (-2.0)\n",
      "Epoch 014/047 | Loss 0.0112 | Win/lose count 3.5/2.0 (1.5)\n",
      "Epoch 015/047 | Loss 0.0027 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 016/047 | Loss 0.0094 | Win/lose count 5.0/3.0 (2.0)\n",
      "Epoch 017/047 | Loss 0.0012 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 018/047 | Loss 0.0036 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 019/047 | Loss 0.0027 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 020/047 | Loss 0.0166 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 021/047 | Loss 0.0004 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 022/047 | Loss 0.0143 | Win/lose count 5.0/1.0 (4.0)\n",
      "Epoch 023/047 | Loss 0.0117 | Win/lose count 5.0/5.0 (0.0)\n",
      "Epoch 024/047 | Loss 0.0010 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 025/047 | Loss 0.0072 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 026/047 | Loss 0.0008 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 027/047 | Loss 0.0070 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 028/047 | Loss 0.0066 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 029/047 | Loss 0.0034 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 030/047 | Loss 0.0005 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 031/047 | Loss 0.0044 | Win/lose count 2.0/0 (2.0)\n",
      "Epoch 032/047 | Loss 0.0021 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 033/047 | Loss 0.0057 | Win/lose count 5.0/2.0 (3.0)\n",
      "Epoch 034/047 | Loss 0.0100 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 035/047 | Loss 0.0063 | Win/lose count 2.5/3.0 (-0.5)\n",
      "Epoch 036/047 | Loss 0.0016 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 037/047 | Loss 0.0123 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 038/047 | Loss 0.0057 | Win/lose count 4.0/3.0 (1.0)\n",
      "Epoch 039/047 | Loss 0.0043 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 040/047 | Loss 0.0057 | Win/lose count 5.5/1.0 (4.5)\n",
      "Epoch 041/047 | Loss 0.0101 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 042/047 | Loss 0.0145 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 043/047 | Loss 0.0043 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 044/047 | Loss 0.0086 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 045/047 | Loss 0.0040 | Win/lose count 4.0/1.0 (3.0)\n",
      "Epoch 046/047 | Loss 0.0025 | Win/lose count 4.0/4.0 (0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(input_shape=(5, 5, self.n_state), kernel_size=1, filters=128))\n",
    "        model.add(Conv2D(kernel_size=3, filters=64))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/047 | Loss 0.0068 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 001/047 | Loss 0.0014 | Win/lose count 6.5/5.0 (1.5)\n",
      "Epoch 002/047 | Loss 0.0083 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 003/047 | Loss 0.0069 | Win/lose count 6.5/7.0 (-0.5)\n",
      "Epoch 004/047 | Loss 0.0005 | Win/lose count 2.5/2.0 (0.5)\n",
      "Epoch 005/047 | Loss 0.0119 | Win/lose count 7.5/4.0 (3.5)\n",
      "Epoch 006/047 | Loss 0.0188 | Win/lose count 8.0/6.0 (2.0)\n",
      "Epoch 007/047 | Loss 0.0166 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 008/047 | Loss 0.0129 | Win/lose count 2.0/1.0 (1.0)\n",
      "Epoch 009/047 | Loss 0.0026 | Win/lose count 4.5/2.0 (2.5)\n",
      "Epoch 010/047 | Loss 0.0031 | Win/lose count 7.0/5.0 (2.0)\n",
      "Epoch 011/047 | Loss 0.0031 | Win/lose count 4.0/0 (4.0)\n",
      "Epoch 012/047 | Loss 0.0053 | Win/lose count 4.5/3.0 (1.5)\n",
      "Epoch 013/047 | Loss 0.0041 | Win/lose count 8.0/3.0 (5.0)\n",
      "Epoch 014/047 | Loss 0.0087 | Win/lose count 11.0/5.0 (6.0)\n",
      "Epoch 015/047 | Loss 0.0028 | Win/lose count 8.0/1.0 (7.0)\n",
      "Epoch 016/047 | Loss 0.0068 | Win/lose count 3.5/6.0 (-2.5)\n",
      "Epoch 017/047 | Loss 0.0029 | Win/lose count 8.5/2.0 (6.5)\n",
      "Epoch 018/047 | Loss 0.0119 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 019/047 | Loss 0.0071 | Win/lose count 11.5/4.0 (7.5)\n",
      "Epoch 020/047 | Loss 0.0271 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 021/047 | Loss 0.0030 | Win/lose count 8.5/2.0 (6.5)\n",
      "Epoch 022/047 | Loss 0.0073 | Win/lose count 7.0/0 (7.0)\n",
      "Epoch 023/047 | Loss 0.0064 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 024/047 | Loss 0.0069 | Win/lose count 12.5/5.0 (7.5)\n",
      "Epoch 025/047 | Loss 0.0130 | Win/lose count 5.0/6.0 (-1.0)\n",
      "Epoch 026/047 | Loss 0.0130 | Win/lose count 7.5/2.0 (5.5)\n",
      "Epoch 027/047 | Loss 0.0088 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 028/047 | Loss 0.0190 | Win/lose count 7.5/3.0 (4.5)\n",
      "Epoch 029/047 | Loss 0.0047 | Win/lose count 10.5/2.0 (8.5)\n",
      "Epoch 030/047 | Loss 0.0081 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 031/047 | Loss 0.0063 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 032/047 | Loss 0.0097 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 033/047 | Loss 0.0023 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 034/047 | Loss 0.0050 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 035/047 | Loss 0.0077 | Win/lose count 5.5/3.0 (2.5)\n",
      "Epoch 036/047 | Loss 0.0047 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 037/047 | Loss 0.0087 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 038/047 | Loss 0.0069 | Win/lose count 6.0/3.0 (3.0)\n",
      "Epoch 039/047 | Loss 0.0098 | Win/lose count 9.0/3.0 (6.0)\n",
      "Epoch 040/047 | Loss 0.0048 | Win/lose count 5.0/0 (5.0)\n",
      "Epoch 041/047 | Loss 0.0067 | Win/lose count 8.5/3.0 (5.5)\n",
      "Epoch 042/047 | Loss 0.0043 | Win/lose count 10.0/3.0 (7.0)\n",
      "Epoch 043/047 | Loss 0.0078 | Win/lose count 6.5/3.0 (3.5)\n",
      "Epoch 044/047 | Loss 0.0023 | Win/lose count 2.0/4.0 (-2.0)\n",
      "Epoch 045/047 | Loss 0.0048 | Win/lose count 6.0/2.0 (4.0)\n",
      "Epoch 046/047 | Loss 0.0072 | Win/lose count 11.0/6.0 (5.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAFzltZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTcgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDE6MHgxMTEgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTAgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTggbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAC12WIhAA3//72h/gU2VgT/lm//Q1/3I/bj6z9cWMhBN9aryHowBkvtR/m/6xRbOmelAf34AiUAHNuGcKR2Sd444SUmEXqj4FLgJ9+BTSZFPo2agQvVCkPM7qf31iYfdglpuAvWl75ARRTmUgfKFj8jUjtPBrQ5jBScwtuDoIoZoFB4PArTo0Ad+yPwkaTobWieHx3dJPokJYXAeAucp+yclGFmb5XUxnYzwHA2wLVYl9qnmN5gNuIYmpDH6flEysLr2TYltaNmmPAineyxrOtp1lQgvIJt0JlqnNTSndYC1MmSibVNspJhXYC2mJ9xoZ/JGq6plGzN2phz3tYJiylaieHi6hV+QzPBoH3EEmdmIVXP03aXg9hfdEME5m56QsYzFgRVqnGRRPDLXG0JAcGpEDigki0IfKrAaCTUbATTpswPh3tHkEyuV1K0eT4Jbd2ZfOsZoe2hHuRPLA9WCSzhlkHQEw2kEYaPbIY4H8CNie8pI6zmIAn1j7+GC14N+1xUCFm8g8jWHt2ia/HJS9pjX4TbewF2kVapSpD6I9EFLrDuSPC/uIP4UwmlH011oqcaWjWazMEOaMzJMtuA0qiqiZOlDamAXsPbfkDBFy4lvyXC2foJTIkqa4A4pvNy7B+zKx14e1sevW5dSFxscKEpAD1IvTwNcVzofvYemP5DeaFYwXBy6/FsAbmOYvsEMjic/a28Urfnqli2I2uspDWbOzjEGR/AhLb4WzyDACpdAUUQGw2o3GtBmhyLkAUshzQlCLAJzL20RqxETIQY/lpMvaNVPxHXRp4MQt2C0iECDaL2v2nN5FXz+emTgYWyErrIEPktyomBn5w+1opQ2HNtNKo+PPoWPOsw+IY0AaG5d3+/SzyQD1e9rycX5m1ekvRmYZU3gj3b8tCBghbzeSiDT3BY78nR0jh9+UhXGDkzv/ixWFg9MmeRyYi19HvnQDT1gMYJWCwAkMAAAAMQZoibEN//qeEAAEnAAAADwGeQXkK/wAJEqRus9WgnwAAABBBmkQ8IZMphDf//qeEAAEnAAAADwGeY2pCvwAJEqRus9WgnwAAABJBmmZJ4Q8mUwU8N//+p4QAAScAAAAPAZ6FakK/AAkSpG6z1aCfAAAAEkGaiEnhDyZTBTw3//6nhAABJwAAAA8BnqdqQr8ACRKkbrPVoJ4AAAASQZqqSeEPJlMFPDP//p4QAAR8AAAADwGeyWpCvwAJEqRus9WgnwAAABpBmstJ4Q8mUwIZ//6eEAAsfvAAf3dpzdxdwgAAABtBmuxJ4Q8mUwIb//6nhAAQ1AFm22gMAmv7wTAAAAAZQZsNSeEPJlMCG//+p4QAEVHzHJO42YLWkQAAABhBmy5J4Q8mUwId//6plgANlUgzPwhxtnEAAAAlQZtSSeEPJlMCG//+p4QAHR9g/93ISDt9C/2FeXe8Cm0t2uW54QAAABZBn3BFETwv/wARXPC+/XGqXIQRJKFwAAAADwGfj3RCvwAXTLBg2Y4mDwAAABABn5FqQr8AF+Zua48VbVKhAAAAGkGblUmoQWiZTAhv//6nhAAc84z/Vb5j8TjgAAAAEUGfs0URLCv/ABfnaf9HJFYXAAAAEAGf1GpCvwAX51TyYHr3mYEAAAAZQZvYSahBbJlMCG///qeEAB0fYPXsz4IspwAAABFBn/ZFFSwr/wAYhm5rjLB++wAAAA4BnhdqQr8AGIJDMm5L9wAAABlBmhlJqEFsmUwIb//+p4QAHG9g9ezPgiyvAAAAHUGaO0nhClJlMFFSw3/+p4QAKfitmJ/q7fGn8iSZAAAAEAGeWmpCvwAhu0Qm4z69QAgAAAAZQZpcSeEOiZTAhv/+p4QAP2cZ/qR0aQ1dIQAAABZBmmBJ4Q8mUwIb//6nhAA+Bxn+q5/xAAAADkGenkURPC//ACW0AHtgAAAAEAGevXRCvwA0OonPcJFWG4AAAAAQAZ6/akK/ADYVlDP5rwKuzQAAACJBmqJJqEFomUwU8N/+p4QAm3w58yyxMjtxq1TISGzzb0qwAAAAEAGewWpCvwB8WeBdf24fXSEAAAAZQZrDSeEKUmUwIb/+p4QA7Bxn+q3zH4g3oAAAABlBmuRJ4Q6JlMCHf/6plgDCxYbot3MfgKPhAAAAEkGbCEnhDyZTAh3//qmWAACVgQAAAAxBnyZFETwv/wAAsoEAAAAPAZ9FdEK/AStUjiOy7Kk3AAAADwGfR2pCvwErVI3WerPSDgAAABNBm0xJqEFomUwId//+qZYAAJWAAAAADEGfakURLC//AACygQAAAA8Bn4l0Qr8BK1SOI7LsqTcAAAAPAZ+LakK/AStUjdZ6s9IOAAAAEkGbkEmoQWyZTAhv//6nhAABJwAAAAxBn65FFSwv/wAAsoEAAAAPAZ/NdEK/AStUjiOy7Kk3AAAADwGfz2pCvwErVI3WerPSDgAAABJBm9RJqEFsmUwIZ//+nhAABHwAAAAMQZ/yRRUsL/8AALKBAAAADwGeEXRCvwErVI4jsuypNwAAAA8BnhNqQr8BK1SN1nqz0g4AAAAbQZoVSahBbJlMCGf//p4QBdPRqAyPOt0DFbH/AAAAG0GaNknhClJlMCG//qeEA5KGf6hlLoEJ/VJgQAAAABhBmldJ4Q6JlMCG//6nhAPYPCnXnPza8W0AAAAgQZp7SeEPJlMCG//+p4QERV8qmTSIRRz7ojv9oZKH0wMAAAAVQZ6ZRRE8L/8BZQ9DUJdM5cS8PPsqAAAAEAGeuHRCvwHfJA1tMaBeUEEAAAAPAZ66akK/ATaTKZtmRrI+AAAAGUGavEmoQWiZTAhv//6nhAF/PmPIxP8bcbUAAAAXQZrfSeEKUmUwIb/+p4QBjj6Qwf5vcrcAAAAPQZ79RTRMK/8BNpNw1mpAAAAADwGfHmpCvwE3DWBdf37UwAAAACtBmwNJqEFomUwIZ//+nhAUvjCcvMsrnvHzLEsF8yybB07dD4fkfVMaAJBxAAAAFUGfIUURLC//AYfwjv50zi072MBwMAAAAA8Bn0B0Qr8B7EQzIaBmcbMAAAAPAZ9CakK/AgthHkuZ7ukPAAAAGUGbREmoQWyZTAhn//6eEBYr3GhoH9rjDPkAAAAYQZtlSeEKUmUwIb/+p4QG4+Y8kGPyu6NnAAAAGEGbhknhDomUwIb//qeEB6xmPJBj8n2jPwAAABlBm6dJ4Q8mUwId//6plgR4LK405/u7gLOBAAAAG0Gby0nhDyZTAhv//qeEC0P9aPTC9746XPIf4AAAABBBn+lFETwv/wHp9nhvZEjAAAAADwGeCHRCvwKRzBg2Y2hjewAAAA8BngpqQr8CrzRvVX8sO6AAAAAaQZoOSahBaJlMCG///qeEDOtaQRFan+eFg7oAAAAPQZ4sRREsK/8Crk3BKKKBAAAADQGeTWpCvwKwNItpRRUAAAATQZpQSahBbJlMFEw3//6nhAABJwAAABABnm9qQr8CrebrKhWDVFFAAAAAEkGacknhClJlMFLDf/6nhAABJwAAABABnpFqQr8CrebrKhWDVFFBAAAAEkGalEnhDomUwUTDf/6nhAABJwAAABABnrNqQr8CrebrKhWDVFFAAAAAEkGatknhDyZTBTw3//6nhAABJwAAABABntVqQr8CrebrKhWDVFFAAAAAEkGa2EnhDyZTBTw3//6nhAABJwAAABABnvdqQr8CrebrKhWDVFFBAAAAEkGa+knhDyZTBTw3//6nhAABJwAAABABnxlqQr8CrebrKhWDVFFBAAAAEkGbHEnhDyZTBTw3//6nhAABJwAAABABnztqQr8CrebrKhWDVFFBAAAAEkGbPknhDyZTBTw3//6nhAABJwAAABABn11qQr8CrebrKhWDVFFAAAAAEkGbQEnhDyZTBTw3//6nhAABJwAAABABn39qQr8CrebrKhWDVFFBAAAAEkGbYknhDyZTBTw3//6nhAABJwAAABABn4FqQr8CrebrKhWDVFFBAAAAEkGbhEnhDyZTBTw3//6nhAABJwAAABABn6NqQr8CrebrKhWDVFFBAAAAEkGbpknhDyZTBTw3//6nhAABJwAAABABn8VqQr8CrebrKhWDVFFBAAAAEkGbyEnhDyZTBTw3//6nhAABJwAAABABn+dqQr8CrebrKhWDVFFAAAAAEkGb6knhDyZTBTw3//6nhAABJwAAABABnglqQr8CrebrKhWDVFFBAAAAEkGaDEnhDyZTBTw3//6nhAABJwAAABABnitqQr8CrebrKhWDVFFAAAAAEkGaLknhDyZTBTw3//6nhAABJwAAABABnk1qQr8CrebrKhWDVFFBAAAAGEGaT0nhDyZTAhv//qeEDOteQGwCVwjCLwAAABtBmnBJ4Q8mUwId//6plgYfS6Bw/xImHR7KYMAAAAAaQZqUSeEPJlMCG//+p4QM/jJbt5HAJr9CZswAAAATQZ6yRRE8L/8CAeEguJHGJQEp3QAAABABntF0Qr8Cdok8jYsxNBUwAAAADwGe02pCvwKvYjyXM9QxswAAABhBmtdJqEFomUwIb//+p4QM+0CRxQnd42cAAAARQZ71RREsK/8Crk+c6x4RyWUAAAAOAZ8WakK/ArA0LsBUpI0AAAAcQZsYSahBbJlMCHf//qmWAUztqAf3hagn50JCwQAAABpBmzxJ4QpSZTAh3/6plgbaHCTZct2l9cZbQAAAABNBn1pFNEwv/wIB4R+KvAs5iFkfAAAAEAGfeXRCvwJ2iTyNizE0FTAAAAAPAZ97akK/Aq9iPJcz1DGzAAAAEkGbYEmoQWiZTAhv//6nhAABJwAAAAxBn55FESwv/wAAsoAAAAAQAZ+9dEK/ArBAHNEhHOUUUAAAABABn79qQr8Crta7gOdZlh3RAAAAEkGbpEmoQWyZTAhv//6nhAABJwAAAAxBn8JFFSwv/wAAsoEAAAAQAZ/hdEK/ArBAHNEhHOUUUAAAABABn+NqQr8Crta7gOdZlh3RAAAAGkGb5UmoQWyZTAhv//6nhAz3E/lME3oCMIuBAAAAG0GaBknhClJlMCHf/qmWBh9LoHD/EiYdHspgwQAAABhBmipJ4Q6JlMCHf/6plgba4937x58kp6UAAAATQZ5IRRE8L/8CAeEguJHGJQEp3QAAABABnmd0Qr8Cdok8jYsxNBUwAAAADwGeaWpCvwKvYjyXM9QxswAAABNBmm5JqEFomUwId//+qZYAAJWAAAAADEGejEURLC//AACygAAAABABnqt0Qr8CsEAc0SEc5RRRAAAAEAGerWpCvwKu1ruA51mWHdEAAAATQZqySahBbJlMCHf//qmWAACVgQAAAAxBntBFFSwv/wAAsoAAAAAQAZ7vdEK/ArBAHNEhHOUUUAAAABABnvFqQr8Crta7gOdZlh3RAAAAEkGa9kmoQWyZTAhv//6nhAABJwAAAAxBnxRFFSwv/wAAsoAAAAAQAZ8zdEK/ArBAHNEhHOUUUQAAABABnzVqQr8Crta7gOdZlh3QAAAAEkGbOkmoQWyZTAhv//6nhAABJwAAAAxBn1hFFSwv/wAAsoEAAAAQAZ93dEK/ArBAHNEhHOUUUAAAABABn3lqQr8Crta7gOdZlh3RAAAAGkGbe0moQWyZTAhv//6nhAz3E/lME3oCMIuAAAAAG0GbnEnhClJlMCHf/qmWBh9LoHD/EiYdHspgwQAAABFBm6BJ4Q6JlMCG//6nhAABJwAAAAxBn95FETwv/wAAsoAAAAAQAZ/9dEK/AZN5N0dt8KjpgAAAAA8Bn/9qQr8BkwWNErnl0ZUAAAAcQZvkSahBaJlMCG///qeEDOtapj/Tbt46d6RJwAAAABVBngJFESwv/wIB4R38+ixag8oyndEAAAAQAZ4hdEK/AnaJPI2LMTQVMAAAAA8BniNqQr8Cr2I8lzPUMbMAAAAYQZolSahBbJlMCG///qeEDPtAkcUJ3eNnAAAAG0GaRknhClJlMCHf/qmWAUztqAf3hagn50JCwQAAABhBmmpJ4Q6JlMCG//6nhAz+Mlu3jp3pEnEAAAASQZ6IRRE8L/8CAeEftyOYhZHwAAAAEAGep3RCvwJ2iTyNizE0FTAAAAAPAZ6pakK/Aq9iPJcz1DGzAAAAGEGarUmoQWiZTAhv//6nhAz7QJHFCd3jZgAAABFBnstFESwr/wKuT5zrHhHJZQAAAA4BnuxqQr8CsDQuwFSkjQAAABtBmu5JqEFsmUwIb//+p4QCk9lYEJ69mfAFsVMAAAAbQZsPSeEKUmUwId/+qZYBN/AQB/eFqCfpIkbBAAAAGkGbM0nhDomUwId//qmWBePSMz3U3aX1xl3AAAAAFUGfUUURPC//Aeqer7z6LFqwS3tfMAAAABABn3B0Qr8CXxk8jYsxNBWxAAAADwGfcmpCvwKRYjyXM9QxvQAAABNBm3dJqEFomUwId//+qZYAAJWAAAAADEGflUURLC//AACygQAAAA8Bn7R0Qr8Cr3HdIS3FoYsAAAAPAZ+2akK/Aq3miDHToKKLAAAAE0Gbu0moQWyZTAh3//6plgAAlYEAAAAMQZ/ZRRUsL/8AALKAAAAADwGf+HRCvwKvcd0hLcWhiwAAAA8Bn/pqQr8CreaIMdOgoooAAAASQZv/SahBbJlMCG///qeEAAEnAAAADEGeHUUVLC//AACygQAAAA8Bnjx0Qr8Cr3HdIS3FoYsAAAAPAZ4+akK/Aq3miDHToKKKAAAAEkGaI0moQWyZTAhv//6nhAABJwAAAAxBnkFFFSwv/wAAsoAAAAAPAZ5gdEK/Aq9x3SEtxaGLAAAADwGeYmpCvwKt5ogx06CiigAAABJBmmdJqEFsmUwIZ//+nhAABH0AAAAMQZ6FRRUsL/8AALKBAAAADwGepHRCvwKvcd0hLcWhiwAAAA8BnqZqQr8CreaIMdOgoosAAAAbQZqpS6hCEFskRggoB/IB/YeAUTCv/jhAABFwAAAAIwGeyGpCvwKvNG/AJbkrO3uLAR/MXVGmMXrmi76ggfeDZzRMAAAL6G1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAsSdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAAKim1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACjVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAn1c3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAXAY3R0cwAAAAAAAAC2AAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAQAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAMAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAQAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABX4AAAAQAAAAEwAAABQAAAATAAAAFgAAABMAAAAWAAAAEwAAABYAAAATAAAAHgAAAB8AAAAdAAAAHAAAACkAAAAaAAAAEwAAABQAAAAeAAAAFQAAABQAAAAdAAAAFQAAABIAAAAdAAAAIQAAABQAAAAdAAAAGgAAABIAAAAUAAAAFAAAACYAAAAUAAAAHQAAAB0AAAAWAAAAEAAAABMAAAATAAAAFwAAABAAAAATAAAAEwAAABYAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAHwAAAB8AAAAcAAAAJAAAABkAAAAUAAAAEwAAAB0AAAAbAAAAEwAAABMAAAAvAAAAGQAAABMAAAATAAAAHQAAABwAAAAcAAAAHQAAAB8AAAAUAAAAEwAAABMAAAAeAAAAEwAAABEAAAAXAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABYAAAAUAAAAFgAAABQAAAAWAAAAFAAAABwAAAAfAAAAHgAAABcAAAAUAAAAEwAAABwAAAAVAAAAEgAAACAAAAAeAAAAFwAAABQAAAATAAAAFgAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAeAAAAHwAAABwAAAAXAAAAFAAAABMAAAAXAAAAEAAAABQAAAAUAAAAFwAAABAAAAAUAAAAFAAAABYAAAAQAAAAFAAAABQAAAAWAAAAEAAAABQAAAAUAAAAHgAAAB8AAAAVAAAAEAAAABQAAAATAAAAIAAAABkAAAAUAAAAEwAAABwAAAAfAAAAHAAAABYAAAAUAAAAEwAAABwAAAAVAAAAEgAAAB8AAAAfAAAAHgAAABkAAAAUAAAAEwAAABcAAAAQAAAAEwAAABMAAAAXAAAAEAAAABMAAAATAAAAFgAAABAAAAATAAAAEwAAABYAAAAQAAAAEwAAABMAAAAWAAAAEAAAABMAAAATAAAAHwAAACcAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 3.0/0. Average score (6.0)\n",
      "Win/lose count 5.0/0. Average score (8.0)\n",
      "Win/lose count 1.0/0. Average score (6.0)\n",
      "Win/lose count 1.0/0. Average score (5.0)\n",
      "Win/lose count 1.5/0. Average score (4.6)\n",
      "Win/lose count 0.5/0. Average score (4.0)\n",
      "Win/lose count 0.5/0. Average score (3.5714285714285716)\n",
      "Win/lose count 0.5/1.0. Average score (3.0)\n",
      "Win/lose count 0/0. Average score (2.6666666666666665)\n",
      "Win/lose count 0.5/0. Average score (2.5)\n",
      "Final score: 2.5\n",
      "Test of the FC\n",
      "Win/lose count 3.5/1.0. Average score (5.0)\n",
      "Win/lose count 0/0. Average score (2.5)\n",
      "Win/lose count 0/0. Average score (1.6666666666666667)\n",
      "Win/lose count 2.0/2.0. Average score (1.25)\n",
      "Win/lose count 0/0. Average score (1.0)\n",
      "Win/lose count 0/0. Average score (0.8333333333333334)\n",
      "Win/lose count 0/0. Average score (0.7142857142857143)\n",
      "Win/lose count 1.5/2.0. Average score (0.5)\n",
      "Win/lose count 0/1.0. Average score (0.2222222222222222)\n",
      "Win/lose count 0.5/0. Average score (0.3)\n",
      "Final score: 0.3\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test9.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test9.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important issue that we can clearly notice is that the agent tends to stay \"stuck\" between two positions which significantly slows down the exploration of the map. (This issue will be tackled in the next question). While two models face the same issue, the agent seem to be stuck very locally (typically between two postions) for the CNN while it's stuck in a local \"region\" for the Fully Connected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    pass\n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        pass\n",
    "    \n",
    "## use those samples of code:\n",
    "#In train explore:\n",
    "state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "## In Environment exploring:\n",
    "# You will have to change n_state to 3 because you will use one more layer!\n",
    "reward = 0\n",
    "if train:\n",
    "    reward = -self.malus_position[self.x, self.y]\n",
    "self.malus_position[self.x, self.y] = 0.1\n",
    "\n",
    "reward = reward + self.board[self.x, self.y]\n",
    "# 3 \"feature\" states instead of 2\n",
    "state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnvironmentExploring(Environment):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        super(EnvironmentExploring, self).__init__(grid_size, max_time, temperature)\n",
    "        # record of visited cells\n",
    "        self.visited = np.ones((grid_size, grid_size))\n",
    "        \n",
    "    def reset(self):\n",
    "        #resets the game and returns the initial state\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        malus = -1.0 * np.random.binomial(1, self.temperature, size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time + 2, self.grid_size * self.scale, self.grid_size * self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus > 0] = 0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0: 2, :] = -1\n",
    "        self.position[:, 0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.visited = np.ones((self.grid_size, self.grid_size))\n",
    "        self.visited[0: 2, :] = -1\n",
    "        self.visited[:, 0:2] = -1\n",
    "        self.visited[-2:, :] = -1\n",
    "        self.visited[-2:, :] = -1\n",
    "        self.board[self.x, self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size, 1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size, 1),\n",
    "                        self.visited.reshape(self.grid_size, self.grid_size, 1)), axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n",
    "\n",
    "    def act(self, action):\n",
    "        # returns the new state, reward and decides if the game ends.\"\"\"\n",
    "        \n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2, :] =  -1\n",
    "        self.position[:, 0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size - 3:\n",
    "                self.x = self.x - 1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x + 1\n",
    "            else:\n",
    "                self.x = self.x - 1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            raise RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        is_unvisited_cell = self.visited[self.x, self.y]\n",
    "        reward = self.board[self.x, self.y]\n",
    "        exploration_reward = is_unvisited_cell * 0.2 - (1 - is_unvisited_cell) * 0.6\n",
    "        self.board[self.x, self.y] = 0\n",
    "        self.visited[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size, 1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size, 1),\n",
    "                        self.visited.reshape(self.grid_size, self.grid_size, 1)), axis=2)\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "\n",
    "        return state, reward, exploration_reward, game_over\n",
    "\n",
    "\n",
    "def train_explore(agent, env, epoch, prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "    # Decreasing exploration rate\n",
    "    range_epsilon = np.clip(np.geomspace(0.8, 1e-2, epoch), 0.1, np.inf)\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "        # Set exploration rate\n",
    "        agent.set_epsilon(range_epsilon[e])\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, exploration_reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose - reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            total_reward = reward + exploration_reward\n",
    "            loss = agent.reinforce(prev_state, state,  action, total_reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix + str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win - lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/047 | Loss 0.0558 | Win/lose count 13.0/18.0 (-5.0)\n",
      "Epoch 001/047 | Loss 0.0413 | Win/lose count 10.0/13.0 (-3.0)\n",
      "Epoch 002/047 | Loss 0.0428 | Win/lose count 11.5/16.0 (-4.5)\n",
      "Epoch 003/047 | Loss 0.0756 | Win/lose count 21.0/16.0 (5.0)\n",
      "Epoch 004/047 | Loss 0.0328 | Win/lose count 18.0/16.0 (2.0)\n",
      "Epoch 005/047 | Loss 0.0748 | Win/lose count 19.5/16.0 (3.5)\n",
      "Epoch 006/047 | Loss 0.0600 | Win/lose count 19.0/11.0 (8.0)\n",
      "Epoch 007/047 | Loss 0.0629 | Win/lose count 23.0/11.0 (12.0)\n",
      "Epoch 008/047 | Loss 0.0628 | Win/lose count 20.5/15.0 (5.5)\n",
      "Epoch 009/047 | Loss 0.0505 | Win/lose count 26.5/13.0 (13.5)\n",
      "Epoch 010/047 | Loss 0.0429 | Win/lose count 27.0/7.0 (20.0)\n",
      "Epoch 011/047 | Loss 0.0551 | Win/lose count 16.0/6.0 (10.0)\n",
      "Epoch 012/047 | Loss 0.0386 | Win/lose count 13.0/7.0 (6.0)\n",
      "Epoch 013/047 | Loss 0.0771 | Win/lose count 18.5/12.0 (6.5)\n",
      "Epoch 014/047 | Loss 0.0503 | Win/lose count 22.0/9.0 (13.0)\n",
      "Epoch 015/047 | Loss 0.0804 | Win/lose count 18.0/17.0 (1.0)\n",
      "Epoch 016/047 | Loss 0.0800 | Win/lose count 20.0/8.0 (12.0)\n",
      "Epoch 017/047 | Loss 0.0583 | Win/lose count 28.5/11.0 (17.5)\n",
      "Epoch 018/047 | Loss 0.0597 | Win/lose count 17.5/16.0 (1.5)\n",
      "Epoch 019/047 | Loss 0.0599 | Win/lose count 21.0/14.0 (7.0)\n",
      "Epoch 020/047 | Loss 0.0585 | Win/lose count 8.5/4.0 (4.5)\n",
      "Epoch 021/047 | Loss 0.0737 | Win/lose count 16.5/7.0 (9.5)\n",
      "Epoch 022/047 | Loss 0.0514 | Win/lose count 10.0/8.0 (2.0)\n",
      "Epoch 023/047 | Loss 0.0787 | Win/lose count 12.0/3.0 (9.0)\n",
      "Epoch 024/047 | Loss 0.0528 | Win/lose count 10.0/8.0 (2.0)\n",
      "Epoch 025/047 | Loss 0.0717 | Win/lose count 24.0/12.0 (12.0)\n",
      "Epoch 026/047 | Loss 0.0502 | Win/lose count 23.0/12.0 (11.0)\n",
      "Epoch 027/047 | Loss 0.0494 | Win/lose count 24.0/4.0 (20.0)\n",
      "Epoch 028/047 | Loss 0.0676 | Win/lose count 16.5/8.0 (8.5)\n",
      "Epoch 029/047 | Loss 0.0617 | Win/lose count 21.5/8.0 (13.5)\n",
      "Epoch 030/047 | Loss 0.0604 | Win/lose count 21.0/11.0 (10.0)\n",
      "Epoch 031/047 | Loss 0.0445 | Win/lose count 25.5/9.0 (16.5)\n",
      "Epoch 032/047 | Loss 0.0414 | Win/lose count 26.0/15.0 (11.0)\n",
      "Epoch 033/047 | Loss 0.0670 | Win/lose count 23.5/11.0 (12.5)\n",
      "Epoch 034/047 | Loss 0.0411 | Win/lose count 22.0/13.0 (9.0)\n",
      "Epoch 035/047 | Loss 0.0664 | Win/lose count 21.0/6.0 (15.0)\n",
      "Epoch 036/047 | Loss 0.0645 | Win/lose count 24.5/17.0 (7.5)\n",
      "Epoch 037/047 | Loss 0.0604 | Win/lose count 19.0/11.0 (8.0)\n",
      "Epoch 038/047 | Loss 0.0517 | Win/lose count 19.0/16.0 (3.0)\n",
      "Epoch 039/047 | Loss 0.0625 | Win/lose count 18.0/5.0 (13.0)\n",
      "Epoch 040/047 | Loss 0.0507 | Win/lose count 25.0/8.0 (17.0)\n",
      "Epoch 041/047 | Loss 0.0692 | Win/lose count 17.5/8.0 (9.5)\n",
      "Epoch 042/047 | Loss 0.0714 | Win/lose count 20.0/2.0 (18.0)\n",
      "Epoch 043/047 | Loss 0.0606 | Win/lose count 11.5/5.0 (6.5)\n",
      "Epoch 044/047 | Loss 0.0772 | Win/lose count 21.5/11.0 (10.5)\n",
      "Epoch 045/047 | Loss 0.0520 | Win/lose count 25.0/8.0 (17.0)\n",
      "Epoch 046/047 | Loss 0.0603 | Win/lose count 24.0/14.0 (10.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAGb9tZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTcgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDE6MHgxMTEgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTAgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTggbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAC1WWIhAA3//72h/gU2VgT/lm//Q1/3I/bj6z9cWMhBN9aryHowBkvtR/m/6xRbOmelAf34AiUAHNuGcKScOL/wKS3VvgUy2E5FS6dCXwyjiSuGgE/sC8LTedFaY7TVo7S8tx+/Y+5Ja/uGuld7UOHhIaCTEorNV6ALqNcNmS8hwBHyVUo3iVOPNsCC/PFQfC0TKs8acVGKAAAlezUKzxmDEIoh0QI8S8iYSfwdddyChC75QJ5z4Cv1Qqe9dg6tE/32AtUojkuOtM3kE+ILqG3naEmk4HnmhWfJ14jHNgIkc40n3VUyaghhLllTfy9Q8l7rVAxnKh5iBENBkQegak619B9FWd1m62OnvgANi35PGranzviGXt5VcdvllH17+tUoV3jKSkEONInbVdDtLLmEF3ulv8Tz0tkoGyADZdFBgqf+RqN1wAEVyZ1Vgvsx1AwG59cZ79L9FBNuAVR3oscoybhmDilvzCbiHIeocEGuySiXNdcOtC+7I0aYGr1cm7LAKAbWWMbLfxyqy5z3B6FpZm7EovoYnHjwv1LZCbDhRuDByUF0nwQMHN1TgfAEMqZ+GFzXUh2B7xBaQpzq8M+HdOnk/Io3ee4fvJi9zCHrbgfR5zQZ7l1N0hfW6oAqsjsonUVZcAAVvUNf6vs5jXBJFwZ8/tbVfLgZCSLAWV+5SYZKDQPwtgy0PFNPeQgqZ83w9Eb/tP1qSRAQjg80cl0DiTKrXKliXOM0JEblSAXvMVd4B+W1Xm7LC8ch0sii6GyaT7m4UzcAFYDqrJLgMDH0whKayC4LfB5KccHJ0LDTjGSuDI4CXpHjIkL1xgnZ4YMfg4f0zfBWEcIj189cCWUUvQmLDZTUaqY3kOhmM9JqZemFKF4w/xu8txCV9lvLN/gq8j5IdCTDkHEOBBylSl9zAQQkPrdYTBXfFQDGxyYSEeRajnF7ufJcuaeSrKB1RwihTLQAJaBAAAAE0GaI2xDP/6eEAQR0jn8Oc31lJwAAAASQZ5BeIV/ANzJoRck3P6uiHUxAAAADwGeYmpCvwDcu3CcEDij4AAAABlBmmRJqEFomUwIb//+p4QBFB8x5GJ/ltlnAAAAHkGahknhClJlMFESwz/+nhAHrmcviC76f33I5z/oOQAAABABnqVqQr8BbLHluGzamNqBAAAAHkGaqEnhDomUwUTDP/6eEB6qcq3BdLdjsWc3zVjAgQAAAA8BnsdqQr8CXs70cNm0qRMAAAAYQZrJSeEPJlMCGf/+nhAij7jQ0D+xLw2YAAAAGEGa6knhDyZTAhn//p4QJ6Zx4E3vnt4P8QAAABhBmwtJ4Q8mUwIZ//6eEC0GceBN754WDugAAAAYQZssSeEPJlMCGf/+nhAtJKxwQgECZcqYAAAAGEGbTUnhDyZTAhv//qeEApPYPXsz4AtipwAAAB1Bm29J4Q8mUwURPDP//p4QCSd031X9OPqxf4+VtQAAABABn45qQr8BiSZJpvpIOJSRAAAAGEGbkEnhDyZTAhn//p4QBNfiH9shj6whZQAAABhBm7FJ4Q8mUwIZ//6eEAMj6+/kSI+sIh4AAAAYQZvSSeEPJlMCG//+p4QAg3x0x/h9W215AAAAH0Gb9EnhDyZTBRE8N//+p4QAf332farZBq2YoSKDh4AAAAAPAZ4TakK/AGmJaVIoEqnzAAAAGUGaFUnhDyZTAhv//qeEAFI91P1HGhIcUkEAAAAfQZo5SeEPJlMCG//+p4QANP7B/Pg+lpVqmQj9z72QbAAAABJBnldFETwv/wAfFNXCDT27EHEAAAAPAZ52dEK/ACsxhAZJcweBAAAAEAGeeGpCvwArLchh9ASDk7gAAAAfQZp7SahBaJlMFPDP/p4QAId85vxpuhQuBTaW7Wb+UQAAABABnppqQr8AHQNQ5vh/ElkwAAAAGUGanEnhClJlMCG//qeEABdfdT9RxoSHR8EAAAAZQZq9SeEOiZTAhv/+p4QADuewf4Tgt0KfwQAAAB5Bmt9J4Q8mUwURPDf//qeEAAm3x0+1Xls+FGt0TGEAAAAPAZ7+akK/AAfEH9UigSwnAAAAHkGa4UnhDyZTBTw7//6plgADGfCj7l7I+qFkKYbT4QAAAA8BnwBqQr8ABPm26UaQ8wsAAAAqQZsFSeEPJlMCG//+p4QADd+y+r4FNfUK/ApUtn4FM7Au5Bboct3beAuBAAAAH0GfI0URPC//AAgufdMut5zLKYoxzLAPBzLIOAKuX8gAAAAQAZ9CdEK/AAS31EifFmKisQAAABABn0RqQr8AC12PHK/txDrBAAAAHkGbSEmoQWiZTAhv//6nhAAVr3U++Gedi4qtZjotwQAAABNBn2ZFESwr/wARXp13D7ZgzOuBAAAAEAGfh2pCvwARWT5zrQwvhMAAAAAaQZuJSahBbJlMCG///qeEAA2PsH+E4LdCqcAAAAAfQZutSeEKUmUwIZ/+nhAAM3PtN28/EP5uHjyA0iaoJQAAABRBn8tFNEwv/wAHxTqM3AxIy6Z6bAAAABABn+p0Qr8ABxOJ4pNsliiAAAAAEAGf7GpCvwAKzY8cr+3EP0EAAAAZQZvuSahBaJlMCGf//p4QAE94Mc/hzm+uaQAAABhBmg9J4QpSZTAhv/6nhAAUj3U4/w+rbrMAAAAZQZowSeEOiZTAhv/+p4QAHlOM/1W+Y/E2YAAAACBBmlRJ4Q8mUwIZ//6eEAC6+8AAy/Ot1xHP6HsbsrqVbgAAABFBnnJFETwv/wAcT7zuq9edaQAAAA8BnpF0Qr8AJsIA6E5L9sAAAAAQAZ6TakK/ACW7RCbjPr0+2AAAABpBmpVJqEFomUwIb//+p4QAR1AFm22fZ81QQQAAABhBmrZJ4QpSZTAhv/6nhABJR8x5GJ/lt1UAAAAcQZrZSeEOiZTAhv/+p4QAcQ4z/V2+NPzzTWBVIQAAABJBnvdFETwr/wBdLIhdhvpecLkAAAAPAZ8YakK/AF0siE4IHGtgAAAAGkGbG0moQWiZTBTwz/6eEAHG9ffptepCRCk5AAAAEAGfOmpCvwBfmbmuPFW0mqAAAAAZQZs8SeEKUmUwIb/+p4QAS746fUcaEhxZQQAAAC5Bm19J4Q6JlMCGf/6eEAHRxty/EI7xf/8QiRNLP/+IL8nWf/8v/h6evHjbme0pAAAAEkGffUURPCv/AGIds1F+Gxr5nwAAABABn55qQr8AYh2o5X9uH3BAAAAAGEGbgEmoQWiZTAhn//6eEALTwY5+l/clswAAABhBm6FJ4QpSZTAhv/6nhAC94rSCET/LbQMAAAAfQZvDSeEOiZTBTRMM//6eEAL3X4PQum+pXsYH6Bh/gQAAABABn+JqQr8An1KN5piraQbAAAAAGUGb5EnhDyZTAhv//qeEAH7B4U6zp91t3oEAAAAXQZoFSeEPJlMCG//+p4QAgo+Y5XDbbXkAAAAZQZomSeEPJlMCHf/+qZYAQn48/fsg3FQE4QAAAB9BmkpJ4Q8mUwIb//6nhABWvdT9qweBNc4zVNbolhbBAAAAEEGeaEURPC//ADOKtSeGSwIAAAAPAZ6HdEK/AEVtCAyS5amAAAAADwGeiWpCvwBFZW6UaQ8UNwAAABpBmo1JqEFomUwIb//+p4QAU/0T/Vb5j8RQQAAAABJBnqtFESwr/wBDdohdhvpedAgAAAAQAZ7MakK/AEVeaJkTSs30wQAAAB1Bms9JqEFsmUwUTDf//qeEAHwB4muNUS/RP8h7iQAAABABnu5qQr8AaYFjXvNKzc3BAAAAHEGa8UnhClJlMFLDf/6nhAC94rZif6u3up+1avgAAAAQAZ8QakK/AJ8o0TImlZtnwAAAABFBmxVJ4Q6JlMCG//6nhAABJwAAAAxBnzNFFTwv/wAAsoAAAAAQAZ9SdEK/AO1YrF5/A5HcQAAAABABn1RqQr8A7RqHP8y3fuzBAAAAHEGbV0moQWiZTBTw3/6nhAEcHzVNZtzXjp9qzlgAAAAQAZ92akK/AOez5jdDkg4oeQAAABhBm3pJ4QpSZTAhn/6eEARX4h/bIY+sIYsAAAASQZ+YRTRMK/8BbMHXd4FNQHXAAAAADgGfuWpCvwFsbdeA2uUbAAAAGkGbu0moQWiZTAhv//6nhAC6e6n6jjQkOEfAAAAAGUGb3EnhClJlMCG//qeEAHc9g/wnBboSYEEAAAAdQZv+SeEOiZTBTRMN//6nhABNvjp91pZmpt0WvVkAAAAQAZ4dakK/AD4hEzTfSQcfmAAAABxBmgBJ4Q8mUwU8N//+p4QAM777PutLM1Nui2IYAAAAEAGeP2pCvwAqDchh9ASDlAkAAAAcQZoiSeEPJlMFPDf//qeEACHfHT7rSzNTbotnCAAAABABnkFqQr8AHFVwa48VbUmhAAAAGUGaQ0nhDyZTAhv//qeEABbPdT9RxoSHScAAAAAdQZplSeEPJlMFETw7//6plgAHU9pf1WnedpMGgUsAAAAQAZ6EakK/AAvxLadeAKCAgQAAABZBmolJ4Q8mUwId//6plgADAVIM0A7VAAAAE0Gep0URPC//AAOhEhmgaP1yJYMAAAAQAZ7GdEK/AAT5NaMkt/tXgAAAAA8BnshqQr8ABPrCPJgevq8AAAASQZrNSahBaJlMCG///qeEAAEnAAAAE0Ge60URLC//AAXRNnJm3Dgl0wwAAAAQAZ8KdEK/AAfGMJ+X6UJkYAAAABABnwxqQr8AB8QXnOtDDAfBAAAAGkGbDkmoQWyZTAh3//6plgADGe0vC1BP7EbBAAAAG0GbMknhClJlMCG//qeEAAX/32fcyMLZihHRVQAAABBBn1BFNEwv/wADifw9ddrAAAAAEAGfb3RCvwAE1dWjJLf7W4AAAAAPAZ9xakK/AAMkCxsDlXyBAAAAHEGbdkmoQWiZTAhn//6eEAAWGvdcRz+kdff09aAAAAAQQZ+URREsL/8AA2CrxvYROAAAAA8Bn7N0Qr8AAyTybzzjmYEAAAAQAZ+1akK/AASXaITcZ9exqAAAABpBm7dJqEFsmUwIb//+p4QACKoAs22z7PnxwQAAAB1Bm9lJ4QpSZTBRUsM//p4QADNr7riOf0jr7+mp4QAAABABn/hqQr8ACs2RCbjPr1Z4AAAAGEGb+knhDomUwIb//qeEAA0/sHr2Z8EXCQAAAB1BmhxJ4Q8mUwUVPDf//qeEAAzvsH+WulucE0T9zAAAABABnjtqQr8ACoNuRV4AoJmBAAAAHkGaPknhDyZTBTw3//6nhAAH7B4muNUS/RP58HnKiQAAABABnl1qQr8ABpnbhNxn164kAAAAHUGaQEnhDyZTBTwz//6eEAAfL39+mB84l3XEfVRuAAAAEAGef2pCvwAGmI7c60MMFkEAAAAYQZphSeEPJlMCGf/+nhAAE/902MuTZWDUAAAAGEGagknhDyZTAhv//qeEAAT/3U4/w+rcmwAAABlBmqNJ4Q8mUwIb//6nhAAE2+jn3MihIhbAAAAAKUGaxknhDyZTAhv//qeEAAdH4ErnMsrnvH4FKls/ApnYGKF9VO+B78zBAAAAEkGe5EURPCv/AAX52zeApH18pQAAABABnwVqQr8ABfnajlf24kRBAAAAGUGbCUmoQWiZTAhn//6eEAAsPBjn6MCBSi8AAAAPQZ8nRREsK/8ACSyuBO1AAAAADQGfSGpCvwAJMGsPF2oAAAAaQZtKSahBbJlMCG///qeEABFUAWbbZ9nzkkEAAAAZQZtrSeEKUmUwIb/+p4QAGvpE/1W+Y/E9IAAAAB5Bm41J4Q6JlMFNEw3//qeEABu/YP5tLqB4cWQp0hYAAAAQAZ+sakK/ABa6UbzTFW1VYQAAABlBm65J4Q8mUwId//6plgAJD8efv2Qbip3hAAAAH0Gb0knhDyZTAh3//qmWAAYL4Ue/ZetDc5FnKDcTtGEAAAAWQZ/wRRE8L/8ABxPtCp0crkTJPItUgAAAABABng90Qr8ACa7jvK2UPamAAAAADwGeEWpCvwAGSIvmbZkcfQAAABxBmhZJqEFomUwIb//+p4QACw4rZif6u3up+2HIAAAAEEGeNEURLC//AAaZV43sGfgAAAAPAZ5TdEK/AAX5JRCmCV2BAAAAEAGeVWpCvwAI7tEJuM+vWGgAAAAaQZpZSahBbJlMCG///qeEABDUAWbbZ9nzlEEAAAAPQZ53RRUsK/8ADdEtZs5hAAAADwGemGpCvwAOJzhsDlPvgAAAAB5BmptJqEFsmUwUTDf//qeEABr3VqmP9HE/y2SlyMkAAAAQAZ66akK/ABYrCPJgevepgAAAABhBmr5J4QpSZTAhn/6eEABp/X3dpzdxcR0AAAASQZ7cRTRMK/8AIb067u/pFhGBAAAADgGe/WpCvwAhsrruPBCMAAAAGkGa/0moQWiZTAhv//6nhAAo3on+q3zH4lJAAAAAGUGbAEnhClJlMCG//qeEAD4HGf6rfMfiNSEAAAAfQZsiSeEOiZTBTRMO//6plgAgPx5+XS8qzogW41WbgAAAABABn0FqQr8ANMzc1x4q2mVhAAAAGUGbRUnhDyZTAh3//qmWABVPfV9diDcVFTAAAAAPQZ9jRRE8K/8AIbK4ErBBAAAADwGfhGpCvwAWLlA8mCN7gQAAABxBm4lJqEFomUwIb//+p4QAGx9g/zlOvCjW5kJ5AAAAEEGfp0URLC//AA/f8PXWVcEAAAAPAZ/GdEK/ABYk5QpNslYvAAAADwGfyGpCvwAOJzhsDlPvgAAAABlBm81JqEFsmUwIZ//+nhAAaW37219ffbslAAAAEEGf60UVLC//AA/idO/zg6gAAAAPAZ4KdEK/AA4rYGuvi/KAAAAAEAGeDGpCvwAWKx5bhs2qX4EAAAAZQZoOSahBbJlMCGf//p4QAKNwY5/DnN9a3QAAABhBmi9J4QpSZTAhn/6eEAD4FOOfw5zfWjcAAAAbQZpQSeEOiZTAhn/+nhABh5DHP4c+ICmfrOVAAAAAF0GacUnhDyZTAhn//p4QAZFfcYI67HakAAAAGUGakknhDyZTAhv//qeEAGldWkEIn+W26oEAAAAdQZq0SeEPJlMFETwz//6eEAGd9ff0K6NkxbBVCpAAAAAQAZ7TakK/AFZbcirwBP7wgAAAABhBmtVJ4Q8mUwIb//6nhAAtWK0ghE/y3BMAAAAdQZr3SeEPJlMFETw3//6nhABHR8zU2bcZvdT4unwAAAAQAZ8WakK/ADoMweTA9e4ygQAAABxBmxlJ4Q8mUwU8N//+p4QAa91bMT/V291P2rmZAAAAEAGfOGpCvwBa1GiZE0rN20AAAAAcQZs7SeEPJlMFPDP//p4QAnohzpsF6I6+/pe/IQAAABABn1pqQr8AhrzRMiaVm3dAAAAAG0GbXEnhDyZTAhv//qeEAPccZ/qt9VBj/xBqQQAAABhBm31J4Q8mUwIb//6nhAGd6J/qMKEXdMEAAAAfQZufSeEPJlMFETw3//6nhAQuM1TWbX66J/Pg8faekAAAABABn75qQr8B3x/F7ockGkf4AAAAHEGboUnhDyZTBTw3//6nhARLsx+TUBWzFCN7EzEAAAAQAZ/AakK/Ad6y/VHzH4tjQAAAABtBm8VJ4Q8mUwIZ//6eEA027riOfp/um+ugm4EAAAAQQZ/jRRE8L/8BUaBFaUT4OAAAAA8BngJ0Qr8BLrRi4D8s/uEAAAAQAZ4EakK/AcZnzG6HJBxIuQAAABlBmgdJqEFomUwU8M/+nhANfzm+49AtolpBAAAAEAGeJmpCvwHSDwa48VbRsGEAAAAbQZopS+EIQpSRGCCgH8gH9h4BSwr//jhAABFwAAAAJAGeSGpCvwKvY+1BxN2qw0km5apnHtPQXk3ELRpnFRSdJuYYwAAAC3htb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAfkAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAKonRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAfkAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABEAAAARAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAH5AAAAQAAAEAAAAAChptZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAAGUAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAnFbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJhXN0YmwAAACVc3RzZAAAAAAAAAABAAAAhWF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABEAEQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAvYXZjQwH0AA3/4QAXZ/QADZGbKCIR0IAAAAMAgAAAGQeKFMsBAAVo6+PESAAAABhzdHRzAAAAAAAAAAEAAADKAAACAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFUGN0dHMAAAAAAAAAqAAAAAEAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAAFAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAwAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAIAAAQAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAADAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAwAABAAAAAABAAAIAAAAAAIAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACAAAAAACAAACAAAAAAIAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAABQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAACAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAGAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAygAAAAEAAAM8c3RzegAAAAAAAAAAAAAAygAABXwAAAAXAAAAFgAAABMAAAAdAAAAIgAAABQAAAAiAAAAEwAAABwAAAAcAAAAHAAAABwAAAAcAAAAIQAAABQAAAAcAAAAHAAAABwAAAAjAAAAEwAAAB0AAAAjAAAAFgAAABMAAAAUAAAAIwAAABQAAAAdAAAAHQAAACIAAAATAAAAIgAAABMAAAAuAAAAIwAAABQAAAAUAAAAIgAAABcAAAAUAAAAHgAAACMAAAAYAAAAFAAAABQAAAAdAAAAHAAAAB0AAAAkAAAAFQAAABMAAAAUAAAAHgAAABwAAAAgAAAAFgAAABMAAAAeAAAAFAAAAB0AAAAyAAAAFgAAABQAAAAcAAAAHAAAACMAAAAUAAAAHQAAABsAAAAdAAAAIwAAABQAAAATAAAAEwAAAB4AAAAWAAAAFAAAACEAAAAUAAAAIAAAABQAAAAVAAAAEAAAABQAAAAUAAAAIAAAABQAAAAcAAAAFgAAABIAAAAeAAAAHQAAACEAAAAUAAAAIAAAABQAAAAgAAAAFAAAAB0AAAAhAAAAFAAAABoAAAAXAAAAFAAAABMAAAAWAAAAFwAAABQAAAAUAAAAHgAAAB8AAAAUAAAAFAAAABMAAAAgAAAAFAAAABMAAAAUAAAAHgAAACEAAAAUAAAAHAAAACEAAAAUAAAAIgAAABQAAAAhAAAAFAAAABwAAAAcAAAAHQAAAC0AAAAWAAAAFAAAAB0AAAATAAAAEQAAAB4AAAAdAAAAIgAAABQAAAAdAAAAIwAAABoAAAAUAAAAEwAAACAAAAAUAAAAEwAAABQAAAAeAAAAEwAAABMAAAAiAAAAFAAAABwAAAAWAAAAEgAAAB4AAAAdAAAAIwAAABQAAAAdAAAAEwAAABMAAAAgAAAAFAAAABMAAAATAAAAHQAAABQAAAATAAAAFAAAAB0AAAAcAAAAHwAAABsAAAAdAAAAIQAAABQAAAAcAAAAIQAAABQAAAAgAAAAFAAAACAAAAAUAAAAHwAAABwAAAAjAAAAFAAAACAAAAAUAAAAHwAAABQAAAATAAAAFAAAAB0AAAAUAAAAHwAAACgAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 19.5/7.0. Average score (25.0)\n",
      "Win/lose count 11.5/5.0. Average score (19.0)\n",
      "Win/lose count 7.0/3.0. Average score (15.333333333333334)\n",
      "Win/lose count 15.0/4.0. Average score (17.0)\n",
      "Win/lose count 16.0/7.0. Average score (17.2)\n",
      "Win/lose count 15.5/3.0. Average score (18.5)\n",
      "Win/lose count 15.0/2.0. Average score (19.571428571428573)\n",
      "Win/lose count 12.0/4.0. Average score (19.125)\n",
      "Win/lose count 29.0/12.0. Average score (20.77777777777778)\n",
      "Win/lose count 10.0/3.0. Average score (20.1)\n",
      "Final score: 20.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test_explore(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore9.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
